---
permalink: /
# title: "Overview " # ([Curriculum Vitae](https://lijian.ac.cn/files/cv/UCAS_PhD_lijian.pdf))
# excerpt: "Overview"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an Associate Professor and Master's supervisor at the Institute of Information Engineering, Chinese Academy of Sciences (CAS), working on large-scale statistical learning theory and large language models (LLMs).
In July 2020, I obtained my Ph.D. degree from Institute of Information Engineering, CAS, advised by Associate Prof. [Yong Liu](https://liuyonggsai.github.io/) and Prof. Weiping Wang. 


In response to the challenges faced by large language models, such as high computational resource demands and weak foundational theories, my research is dedicated to exploring the underlying principles of large language models. The goal is to design efficient and interpretable lightweight language models, thereby narrowing the gap between foundational theory and practical algorithms. Specific research interests include, but are not limited to:

**Lightweight Language Models**: Investigating the underlying principles of scaling guidelines for large language models to guide the design of the next generation of efficient and deployable lightweight language models. This involves technologies such as model architecture design, model compression, and high-quality instruction fine-tuning.

**LLMs and Deep Learning Theories**: Delving into the unique phenomena of large language models, such as scaling guidelines, contextual learning abilities, complex reasoning capabilities, and the underlying principles of benign overfitting and the double descent phenomenon in deep learning.

**Generalization Theories of Large-Scale Machine Learning Methods**: Researching the generalization theory of large-scale machine learning methods and using the results from generalization theory to enhance large-scale algorithms. This includes studying various methods like federated learning, distributed learning, random features, Nystr√∂m methods, sketching methods, and more.

## Curriculum Vitae ([CV](https://lijian.ac.cn/files/cv/JianLi_CV.pdf))

| Time               | Title                                                       | Institution                               | Research Direction                                    |
|:-------------------| :---------------------------------------------------------- | :---------------------------------------- | :---------------------------------------------------- |
| 2023.10 - present  | Associate Professor | Institute of Information Engineering, CAS | LLMs, Large-scale Statistical Machine Learning  |
| 2020.09 - 2023.10  | Tenure-track Professor     | Institute of Information Engineering, CAS | Large-scale Statistical Machine Learning              |
| 2015.09 - 2020.06  | Ph.D. Candidate                                             | Institute of Information Engineering, CAS | Large-scale Model Selection, Semi-supervised Learning |
| 2011.09 - 2015.06  | Bachelor Candidate                                          | Northeastern University                   | Software Engineering (International class)            |

## Representative Papers [[Full List](https://lijian.ac.cn/publications/)] [[Google Scholar](https://scholar.google.com/citations?hl=en-us&user=IAJpTqYAAAAJ&view_op=list_works&sortby=pubdate)] 
* Optimal Rates for Agnostic Distributed Learning. **Accepted**  <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
To appear in <i>IEEE Transactions On Information Theory</i> (**TIT**). <b>CCF-A</b>. <br>

* Optimal Convergence Rates for Distributed Nystr√∂m Approximation. 
[[pdf]](https://jmlr.org/papers/volume24/21-1049/21-1049.pdf)
[[code]](https://github.com/superlj666/DNystroem) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>Journal of Machine Learning Research</i> (**JMLR**), 2023. <b>CCF-A</b>. <br>

* Convolutional Spectral Kernel Learning with Generalization Guarantees.
[[Paper]](https://doi.org/10.1016/j.artint.2022.103803)
[[Code]](https://github.com/superlj666/CSKN/) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>Artificial Intelligence</i> (**AI**), 2022. <b>CCF-A</b>. <br>

* Optimal Convergence Rates for Agnostic Nystr√∂m Kernel Learning.
[[pdf]](https://openreview.net/forum?id=S3d9SwhRKh)
<br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>International Conference on Machine Learning </i> (**ICML**), 2023. <b>CCF-A</b>.

* Federated learning for non-iid data: From theory to algorithm. 
[[pdf]](https://link.springer.com/chapter/10.1007/978-3-030-89188-6_3)
[[presentation]](https://lijian.ac.cn/files/2021/FL_for_noniid_data_presentation.pdf)
[[üèÜ<b>ÊúÄ‰Ω≥Â≠¶ÁîüËÆ∫ÊñáÂ•ñ</b>]](https://lijian.ac.cn/files/2021/PRICAI-2021-best-student-paper.png) (1/92)<br>
Bojian Wei, <u><b>Jian Li*</b></u>, Yong Liu, Weiping Wang. <br>
<i>Pacific Rim International Conference on Artificial Intelligence</i> (**PRICAI**), 2021. CCF-C.

* Multi-Class Learning: From Theory to Algorithm. 
[[pdf]](https://proceedings.neurips.cc/paper/2018/file/1141938ba2c2b13f5505d7c424ebae5f-Paper.pdf)
[[poster]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-poster.pdf)
[[sildes]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-slides.pdf)
[[3-minute video]](https://youtu.be/mE_RpgWuKK8)
[[code]](https://github.com/superlj666/Multi-Class-Learning-From-Theory-to-Algorithm) <br>
<u><b>Jian Li</b></u>, Yong Liu, Rong Yin, Hua Zhang, Lizhong Ding, Weiping Wang. <br>
<i>Advances in Neural Information Processing Systems 31</i> (**NeurIPS**), 2018. <b>CCF-A</b>.

##  Projects
* National Key R&D Program of China (2022YFB3105302.2), 2022.12 - 2025.11, &yen;1,200,000. <br>
<i> Aggregation and Collaborative Techniques for Cross-platforms Heterogenous Data</i>.

* National Natural Science Foundation of China (No. 62106257), 2022.01 - 2024.12, &yen;300,000. <br>
<i> Large Scale Structured Prediction with Automated Spectral Kernel Learning</i>.

* China Postdoctoral Science Foundation (**Special Support**, No. 2023T160680), 2023.07 - 2024.03, &yen;180,000. <br>
<i>Research on Deep Differentiable Gaussian Processes for Structured Prediction</i>.

* Special Research Assistant Project of CAS, 2020.09 - 2022.09, &yen;800,000. <br>
<i> Large-scale Few-shot Automated Machine Learning</i>.

* Talent Program Class A of Institute of Information Engineering, CAS, Tenure-track Professor, 2023.10 - 2026.09.

* Talent Program Class B of Institute of Information Engineering, CAS, Tenure-track Young Professor, 2020.09 - 2023.10.


## Patents

### Pending

* <u><b>Jian Li</b></u>, Yong Liu, Liubin Wang, Yiguo Yang, Juhong Wang.Neural Network Architecture Search Method, Device, Computer Equipment, and Storage Medium. CNÔºö202011567991.3. App. Date: December 25, 2020.
* <u><b>Jian Li</b></u>, Jiaoyang Li, Bojian Wei, Yong Liu, Weiping Wang. A Federated Learning Method and System Based on Attention Mechanism. CN: 202311073645.3. App. Date: August 24, 2023
* <u><b>Jian Li</b></u>, Jiaoyang Li, Zheng Lin, Yong Liu, Weiping Wang. A Vertical Domain Large Model Method and System Based on Knowledge Distillation and Prompt Engineering. CN: 202311073641.5. App. Date: August 24, 2023.

### Granted

* Hailun Lin, Yong Liu, <u><b>Jian Li</b></u>, Weiping Wang. A Large-Scale Ontology Merging Method that Integrates Representation Learning and Divide-and-Conquer Strategy: China. Granted No.CN110059194A. Granted Date: April 8, 2022.


## Students
- Ph.D. students
  - üéìYilin Kang (2020.09 - 2023.06 ), Differential Privacy. Papers: Computers & Security, CIKM 2022, ICCS 2023. Post-graduation: Researcher in Purple Mountain Laboratories.
  - Xunyu Zhu (2020.09 - present), Neural Architecture Search. Papers: ICDM 2021.
  - Boxuan Che (2022.09 - present), Efficient Graph Neural Networks.
- Master's students
  - üéìBojian Wei (2020.09 - 2022.06), Federated Learning on Heterogenous Data. Papers: PRICAI 2021 (**best student paper award**), ECML-PKDD 2022, TNNLS, IJCNN 2023. Post-graduation: Management Trainee in Bank of China Head Office.
  - Xuning Zhang (2022.09 - present), Federated Learning. **Excellent Bachelor's Thesis in Wuhan University in 2023**.

## Honors and Awards
* PRICAI 2021 best student paper award, 2021.
* Outstanding Graduate of Institute of Information Engineering, CAS, 2021.
* Outstanding Graduates of Beijing, 2020.
* Outstanding Graduates of University of Chinese Academy of Sciences (UCAS), 2020.
* Outstanding Graduates of Institute of Information Engineering, CAS, 2020.
* National Scholarship for Doctoral students, 2019.
* ZhuLiYueHua Scholarship for Excellent Doctoral Student, 2019.
* CAS Presidential Scholarship, 2019.
* National Scholarship for Doctoral students, 2018.
* IIE Presidential Scholarship, 2018.
* ~~AIDU Talents of Baidu Research (Decline)~~, 2020
* ~~Joint Ph.D. Program with Stanford University (Abandon due to COVID-19)~~, 2020.02 - 2021.02

## Academic Service
* Mathematics Guest Editor
* Program committee of Conference: ICML, NeurIPS, ICLR, AAAI, IJCAI, ECAI, etc.
* Reviewers of Journals: TPAMI, JMLR, Pattern Recognition, etc.