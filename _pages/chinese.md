---
title: ""
permalink: /chinese/
author_profile: true
---

**副研究员一级、硕士生导师，中国科学院信息工程研究所** 

**地址：北京市海淀区树村路19号，100085** 

**邮箱：lijian9026 [at] iie.ac.cn, superlj666 [at] gmail.com**

## 研究方向
针对大规模机器学习算法在理论上可解释性不足的问题，致力于研究大语言模型以及其他大规模机器学习算法的基础理论保证，并通过理论结果的指导来改进算法，进而减小基础理论与实际算法之间的差距。我感兴趣的研究方向包括但不限于：
* **大模型和深度学习理论**：研究大语言模型的独特能力（如涌现、顿悟等），以及深度学习中良性过拟合、随着模型参数容量上升测试误差双下降现象的理论研究。
* **高效大模型算法**：高效Transformer、大语言模型压缩方法和参数高效微调（PEFT）。
* **大规模机器学习方法**：为大规模机器学习方法提供理论保证，并基于理论结果改进算法，包括联邦学习、分布式学习、随机特征、Nyström方法、草图方法等。


## 个人履历 ([CV](https://lijian.ac.cn/files/cv/cv_lijian_2023.pdf))

| 时间                | 岗位职级                            | 工作学习单位           | 专业方向                        |
|:------------------- | :----------------------------- |:---------------------- |:-------------------------- |
| 2023.11 - 至今      | 副研究员一级，优才A-预聘研究员      | 中国科学院信息工程研究所 | 大语言模型，大规模统计机器学习|
| 2020.09 - 2023.11  | 助理研究员，博士后，优才B-青年预聘研究员 | 中国科学院信息工程研究所 | 大规模统计机器学习           |
| 2015.09 - 2020.06  | 硕博连读研究生                   | 中国科学院信息工程研究所 | 大规模模型选择，半监督学习    |
| 2011.09 - 2015.06  | 本科生                           | 东北大学               | 软件工程（英语国际班）        |

## 部分论文 [[完整列表](https://lijian.ac.cn/publications/)] [[谷歌学术](https://scholar.google.com/citations?hl=en-us&user=IAJpTqYAAAAJ&view_op=list_works&sortby=pubdate)] 
<i>* 通讯作者</i>

### 预印论文

* A Survey on Model Compression for Large Language Models.
[[pdf]](https://arxiv.org/abs/2308.07633) <br>
Xunyu Zhu, <u><b>Jian Li*</b></u>, Yong Liu, Can Ma, Weiping Wang.  <br>
<i> arXiv:2308.07633</i>. 

### 期刊论文

* Optimal Convergence Rates for Distributed Nyström Approximation. 
[[pdf]](https://jmlr.org/papers/volume24/21-1049/21-1049.pdf)
[[code]](https://github.com/superlj666/DNystroem) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>Journal of Machine Learning Research</i> (**JMLR**), 2023. <b>CCF-A</b>.

* Optimal Convergence for Agnostic Kernel Learning With Random Features.
[[pdf]](https://ieeexplore.ieee.org/abstract/document/10304308)
[[code]](https://github.com/superlj666/Agnostic-RF)
<br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang.  <br>
<i>IEEE Transactions on Neural Networks and Learning Systems</i> (**TNNLS**), 2023. <b>CCF-B</b>.

* Semi-supervised vector-valued learning: Improved bounds and algorithms. 
[[pdf]](https://www.sciencedirect.com/science/article/pii/S0031320323000572) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang.  <br>
<i>Pattern Recognition</i> (**PR**), 2023. <b>CCF-B</b>.

* Improving Differentiable Architecture Search via Self-distillation.
[[pdf]](https://doi.org/10.1016/j.neunet.2023.08.062) <br>
Xunyu Zhu, <u><b>Jian Li*</b></u>, Yong Liu, Weiping Wang.  <br>
<i>Neural Networks</i>. <b>CCF-B</b>.

* Convolutional Spectral Kernel Learning with Generalization Guarantees.
[[Paper]](https://doi.org/10.1016/j.artint.2022.103803)
[[Code]](https://github.com/superlj666/CSKN/) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>Artificial Intelligence</i> (**AIJ**), 2022. <b>CCF-A</b>.

* Non-IID Federated Learning with Sharper Risk Bound.
[[pdf]](https://doi.org/10.1109/TNNLS.2022.3213187) <br>
Bojian Wei, <u><b>Jian Li*</b></u>, Yong Liu, Weiping Wang.  <br>
<i>IEEE Transactions on Neural Networks and Learning Systems</i> (**TNNLS**), 2022. <b>CCF-B</b>.

### 会议论文

* Optimal Convergence Rates for Agnostic Nyström Kernel Learning.
[[pdf]](https://openreview.net/forum?id=S3d9SwhRKh)
<br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>International Conference on Machine Learning </i> (**ICML**), 2023. <b>CCF-A</b>.

* Towards Sharp Analysis for Distributed Learning with Random Features. [[pdf]](https://www.ijcai.org/proceedings/2023/0436.pdf) <br>
<u><b>Jian Li</b></u>, Yong Liu. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2023. <b>CCF-A</b>.

* Ridgeless Regression with Random Features.
[[pdf]](https://www.ijcai.org/proceedings/2022/0445.pdf)
[[code]](https://github.com/superlj666/Ridgeless-Regression-with-Random-Features) <br>
<u><b>Jian Li</b></u>, Yong Liu, Yingying Zhang. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2022. <b>CCF-A</b>.

* Federated learning for non-iid data: From theory to algorithm. 
[[pdf]](https://link.springer.com/chapter/10.1007/978-3-030-89188-6_3)
[[presentation]](https://lijian.ac.cn/files/2021/FL_for_noniid_data_presentation.pdf)
[[🏆<b>最佳学生论文奖</b>]](https://lijian.ac.cn/files/2021/PRICAI-2021-best-student-paper.png)<br>
Bojian Wei, <u><b>Jian Li*</b></u>, Yong Liu, Weiping Wang. <br>
<i>Pacific Rim International Conference on Artificial Intelligence</i> (**PRICAI**), 2021. CCF-C.

* Automated Spectral Kernel Learning. 
[[pdf]](https://ojs.aaai.org/index.php/AAAI/article/view/5892)
[[poster]](https://lijian.ac.cn/files/2020_AAAI_ASKL/2020_AAAI_AKSL_poster.pdf)
[[code]](https://github.com/superlj666/Automated-Spectral-Kernel-Learning) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>AAAI Conference on Artificial Intelligence</i> (**AAAI**), 2020. <b>CCF-A</b>.

* Multi-Class Learning: From Theory to Algorithm. 
[[pdf]](https://proceedings.neurips.cc/paper/2018/file/1141938ba2c2b13f5505d7c424ebae5f-Paper.pdf)
[[poster]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-poster.pdf)
[[sildes]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-slides.pdf)
[[3-minute video]](https://youtu.be/mE_RpgWuKK8)
[[code]](https://github.com/superlj666/Multi-Class-Learning-From-Theory-to-Algorithm) <br>
<u><b>Jian Li</b></u>, Yong Liu, Rong Yin, Hua Zhang, Lizhong Ding, Weiping Wang. <br>
<i>Advances in Neural Information Processing Systems 31</i> (**NeurIPS**), 2018. <b>CCF-A</b>.


## 主持项目

* 中国博士后科学基金特别资助项目 (No. 2023T160680)，2023.07 - 2024.03，18万元。 <br>
面向结构化预测的深度可微高斯过程方法研究。

* 国家重点研发项目子课题 (2022YFB3105302.2)，202212 - 2025.11，120万元。 <br>
跨平台异质性数据聚合与协同技术。

* 国家自然科学基金青年基金 (No. 62106257)，202201 - 2024.12，30万元。 <br>
面向大规模结构化预测的自动谱核学习研究。

* 中国科学院特别研究助理资助，2020.09 - 2022.09，80万元。 <br>
大规模小样本自动化机器学习。

## 发明专利

### 专利申请

* 李健，刘勇，王流斌，杨毅果，王巨宏. 神经网络结构搜索方法、装置、计算机设备和存储介质：中国. 专利申请号：202011567991.3. 2020年12月25日.
* 李健，李骄扬，韦博舰，刘勇，王伟平. 一种基于注意力机制的联邦学习方法及系统：中国. 申请号：202311073645.3. 2023年8月24日.
* 李健，李骄扬，林政，刘勇，王伟平. 一种基于知识蒸馏和提示工程的垂域大模型方法及系统：中国. 申请号：202311073641.5. 2023年8月24日.

### 专利授权

* 林海伦, 刘勇, 李健, 王伟平. 一种融合表示学习和分治策略的大规模本体合并方法：中国. 授权号：CN110059194A. 2022年4月8日.

## 指导学生
- 博士研究生
  - 康艺霖（2018-2023）🎓，差分隐私。 发表论文：Computers & Security、CIKM 2022、ICCS 2023。毕业去向：紫金山实验室。
  - 朱勋宇（2020-至今），神经网络结构搜索。发表论文：ICDM 2021, Neural Networks。
  - 车博轩（2020-至今），高效图神经网络。
- 硕士研究生
  - 韦博舰（2019-2022）🎓，联邦学习。发表论文：PRICAI 2021 (**最佳学生论文奖**)、ECML-PKDD 2022、TNNLS、IJCNN 2023。毕业去向：中国银行总行管培生。
  - 张旭宁（2023-至今），联邦学习。**武汉大学优秀学士论文奖**。

## 荣誉称号
* PRICAI 2021 最佳学生论文奖。
* 2020年北京市优秀毕业生。
* 2020年中国科学院大学（国科大）优秀毕业生。
* 2019年博士研究生国家奖学金。
* 2019年朱李月华优秀博士生奖。
* 2019年中科院院长优秀奖。
* 2018年博士研究生国家奖学金。
* 2018年中科院信工所所长优秀奖。

## 学术服务
- 程序委员或审稿人
  - 会议：ICML、NeurIPS、ICLR、AAAI、IJCAI、ECAI
  - 期刊：TPAMI、JMLR、Pattern Recognition