---
title: "个人简介"
permalink: /chinese/
author_profile: true
redirect_from: 
  - /chinese/
  - /chinese.html
---

**预聘研究员 硕士生导师 中国科学院信息工程研究所**  
**电子邮箱：lijian9026 [at] iie.ac.cn, superlj666 [at] gmail.com**

# 研究方向
本人研究方向为大规模机器学习，针对传统机器学习模型、大语言模型设计进行泛化理论分析并设计高效、可扩展的算法。主要研究内容包括：
- **大规模机器学习**：为大规模机器学习方法（包括联邦学习、分布式学习、Nyström 采样、随机特征、随机投影等大规模算法），提供更紧致的泛化理论分析并设计高效算法。
- **高效大语言模型**：包括高效 Transformer、大模型压缩方法、参数高效微调方法。
- **深度学习及大模型理论**：为深度学习中良好过拟合、测试误差双下降等现象提供理论分析，并尝试理论探索大模型的独有能力（如涌现、顿悟等现象）。

具体研究方法为通过理论分析设计改进大规模机器学习算法，从而弥合机器学习理论、算法与大规模应用之间的巨大差距。

# 部分论文列表 [[Full List](https://lijian.ac.cn/publications/)] [[Github](https://github.com/superlj666)] 
<i>* 通讯作者</i>

* Optimal Convergence Rates for Distributed Nyström Approximation. 
[[Paper]](https://jmlr.org/papers/v24/21-1049.html)
[[Code]](https://github.com/superlj666/DNystroem) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>Journal of Machine Learning Research</i> (**JMLR**), 2023. <b>CCF-A 期刊</b>.

* Optimal Convergence Rates for Agnostic Nyström Kernel Learning.
[[Paper]](https://lijian.ac.cn/files/2023/2023_ICML_Nystroem.pdf)
<br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>International Conference on Machine Learning </i> (**ICML**), 2023. <b>CCF-A 会议</b>.


* Towards Sharp Analysis for Distributed Learning with Random Features. <br>
<b>Jian Li</b>, Yong Liu. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2023. <b>CCF-A 会议</b>.

* Semi-supervised vector-valued learning: Improved bounds and algorithms. 
[[Paper]](https://www.sciencedirect.com/science/article/pii/S0031320323000572) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang.  <br>
<i>Pattern Recognition</i> (**PR**), 2023. <b>CCF-B 期刊 / 中科院一区</b>.

* Non-IID Federated Learning with Sharper Risk Bound.
[[Paper]](https://doi.org/10.1109/TNNLS.2022.3213187) <br>
Bojian Wei, <b>Jian Li*</b>, Yong Liu, Weiping Wang.  <br>
<i>IEEE Transactions on Neural Networks and Learning Systems</i> (**TNNLS**), 2022. <b>CCF-B 期刊 / 中科院一区</b>.

* Convolutional Spectral Kernel Learning with Generalization Guarantees.
[[Paper]](https://doi.org/10.1016/j.artint.2022.103803)
[[Code]](https://github.com/superlj666/CSKN/) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>Artificial Intelligence</i> (**AI**), 2022. <b>CCF-A 期刊 / 中科院一区</b>.

* Non-IID Distributed Learning with Optimal Mixture Weights. 
[[Paper]](https://2022.ecmlpkdd.org/wp-content/uploads/2022/09/sub_1304.pdf) <br>
<b>Jian Li</b>, Bojian Wei, Yong Liu, Weiping Wang. <br>
<i>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</i> (**ECML-PKDD**), 2022. <b>CCF-B 会议</b>.

* Ridgeless Regression with Random Features.
[[Paper]](https://arxiv.org/pdf/2205.00477.pdf)
[[Code]](https://github.com/superlj666/Ridgeless-Regression-with-Random-Features) <br>
<b>Jian Li</b>, Yong Liu, Yingying Zhang. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2022. <b>CCF-A 会议</b>.

* Federated learning for non-iid data: From theory to algorithm. 
[[Paper]](https://lijian.ac.cn/files/2021/FL_for_noniid_data.pdf)
[[Presentation]](https://lijian.ac.cn/files/2021/FL_for_noniid_data_presentation.pdf)<br>
Bojian Wei, <b>Jian Li*</b>, Yong Liu, Weiping Wang. <br>
<i>Pacific Rim International Conference on Artificial Intelligence</i> (**PRICAI**), 2021. CCF-C 会议, <b>
[[最佳学生论文奖]](https://lijian.ac.cn/files/2021/PRICAI-2021-best-student-paper.png)</b>.

* Automated Spectral Kernel Learning. 
[[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/5892/5748)
[[Poster]](https://lijian.ac.cn/files/2020_AAAI_ASKL/2020_AAAI_AKSL_poster.pdf)
[[Code]](https://github.com/superlj666/Automated-Spectral-Kernel-Learning) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>AAAI Conference on Artificial Intelligence</i> (**AAAI**), 2020. <b>CCF-A 会议</b>.

* Multi-Class Learning: From Theory to Algorithm. 
[[Paper]](https://proceedings.neurips.cc/paper/2018/file/1141938ba2c2b13f5505d7c424ebae5f-Paper.pdf)
[[Poster]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-poster.pdf)
[[Sildes]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-slides.pdf)
[[3-minute video]](https://youtu.be/mE_RpgWuKK8)
[[Code]](https://github.com/superlj666/Multi-Class-Learning-From-Theory-to-Algorithm) <br>
<b>Jian Li</b>, Yong Liu, Rong Yin, Hua Zhang, Lizhong Ding, Weiping Wang. <br>
<i>Advances in Neural Information Processing Systems 31</i> (**NeurIPS**), 2018. <b>CCF-A 会议</b>.

# 主持项目
* 国家自然科学基金青年基金 (No. 62106257)，30万元。 <br>
面向大规模结构化预测的自动谱核学习研究。

* 国家重点研发项目子课题 (2022YFB3105302.2)，120万元。 <br>
跨平台异质性数据聚合与协同技术。</i>

* 中国科学院特别研究助理自主，80万元。 <br>
大规模小样本自动化机器学习。

* 中国科学院信息工程研究所优才计划B类，
预聘（正高）研究员。


# 荣誉称号
* PRICAI 2021 最佳学生论文奖
* 2020年北京市优秀毕业生
* 2020年中国科学院大学（国科大）优秀毕业生
* 2019年博士研究生国家奖学金
* 2019年朱李月华优秀博士生奖
* 2019年中科院院长优秀奖
* 2018年博士研究生国家奖学金
* 2018年中科院信工所所长优秀奖


# 教育背景
* 2015.09 - 2020.07，中国科学院大学网络空间安全专业，工学博士，导师：王伟平。
* 2011.09 - 2015.07，东北大学软件工程专业(英语国际班)，工学学士。

# 学术服务
- 程序委员或审稿人
  - 会议：ICML、NeurIPS、ICLR、AAAI、IJCAI、ECAI
  - 期刊：TPAMI、JMLR